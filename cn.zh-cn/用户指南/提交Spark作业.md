# 提交Spark作业<a name="dli_01_0375"></a>

使用DLI提交Spark作业进行实时计算。基本流程如下：

[步骤1：登录华为云](#section3751181910618)

[步骤2：上传数据至OBS](#section10891114913473)

[步骤3：进入DLI Spark作业编辑页面](#section19012773105034)

[步骤4：创建队列](#section122981023152710)

[步骤5：创建程序包](#section21433273112656)

[步骤6：提交Spark作业](#section21590507141153)

## 步骤1：登录华为云<a name="section3751181910618"></a>

使用DLI服务，首先要登录华为云。

1.  打开[华为云](https://www.huaweicloud.com/)首页。
2.  在登录页面输入“账户名“和“密码“，单击“登录“。

## 步骤2：上传数据至OBS<a name="section10891114913473"></a>

提交Spark作业之前，需要在OBS中上传数据文件。

1.  在华为云页面的上方导航栏中，选择“产品“。
2.  在基础服务列表中，单击“存储”中的“对象存储服务OBS”。
3.  在OBS服务产品页，单击“管理控制台“，进入OBS管理控制台页面。
4.  创建一个桶，桶名全局唯一，这里以桶名“obs1”为例。
    1.  单击“创建桶“。
    2.  进入“创建桶”页面，选择“区域”，输入“桶名称”。

        >![](public_sys-resources/icon-note.gif) **说明：** 
        >创建OBS桶时，需要选择与DLI管理控制台相同的区域，不可跨区域执行操作。

    3.  单击“立即创建”。

5.  单击所建桶“obs1”，进入“概览”页面。
6.  单击左侧列表中的“对象”，选择“上传文件”，将需要上传的文件，例如“spark-examples.jar“上传到指定目录，单击“确定“。

    文件上传成功后，待分析的文件路径为“obs://obs1/spark-examples.jar“。


## 步骤3：进入DLI Spark作业编辑页面<a name="section19012773105034"></a>

使用DLI提交Spark作业，需要先进入Spark作业编辑页面。

1.  在华为云页面的上方导航栏，选择“产品“。
2.  在“EI企业智能“列表中，选择“大数据“\>“大数据计算“中的“数据湖探索 DLI“。
3.  在DLI服务产品页，单击“进入控制台“，进入DLI管理控制台页面。第一次进入数据湖探索管理控制台需要进行授权，以获取访问OBS的权限。
4.  单击总览页面“Spark作业”右侧的“创建作业”，进入创建Spark作业页面。

## 步骤4：创建队列<a name="section122981023152710"></a>

第一次提交Spark作业，需要先创建队列，例如创建名为“test”的队列。创建队列的详细介绍请参考[创建队列](创建队列.md)。

## 步骤5：创建程序包<a name="section21433273112656"></a>

提交Spark作业之前需要创建程序包，例如“spark-examples.jar”。详细介绍请参考[创建程序包](创建程序包.md)。

## 步骤6：提交Spark作业<a name="section21590507141153"></a>

1.  在Spark作业编辑页面中，输入相关参数，具体请参考[界面说明](创建Spark作业.md#zh-cn_topic_0115200017_zh-cn_topic_0093946815_section56922894165137)中关于Spark作业编辑页面的说明。
2.  单击Spark作业编辑页面右上方“执行”，阅读并同意隐私协议，单击“确定”。提交作业，页面显示“作业提交成功”。
3.  （可选）可到“作业管理”\>“Spark作业”页面查看提交作业的状态及日志。

    >![](public_sys-resources/icon-note.gif) **说明：** 
    >在DLI管理控制台第一次单击“执行”操作时，需要阅读隐私协议，同意确定后，后续操作将不会再提示。


